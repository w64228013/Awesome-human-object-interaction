# Awesome-human-object-interaction Video [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

Collect some HOI papers based on Video.

## Papers
  - 2021-**CVPR**-Hierarchical Video Prediction Using Relational Layouts for Human-Object Interactions [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Bodla_Hierarchical_Video_Prediction_Using_Relational_Layouts_for_Human-Object_Interactions_CVPR_2021_paper.html)]
  - 2021-**CVPR**-Learning Asynchronous and Sparse Human-Object Interaction in Videos [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Morais_Learning_Asynchronous_and_Sparse_Human-Object_Interaction_in_Videos_CVPR_2021_paper.html)] [[code](https://github.com/RomeroBarata/human_object_interaction)] ![Github stars](https://img.shields.io/github/stars/RomeroBarata/human_object_interaction.svg)
  - 2021-**ICCV**-Weakly Supervised Human-Object Interaction Detection in Video via Contrastive Spatiotemporal Regions [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Li_Weakly_Supervised_Human-Object_Interaction_Detection_in_Video_via_Contrastive_Spatiotemporal_ICCV_2021_paper.html)] [[code](https://github.com/ShuangLI59/weakly-supervised-human-object-detection-video)] ![Github stars](https://img.shields.io/github/stars/ShuangLI59/weakly-supervised-human-object-detection-video.svg)
  - 2021-ICMR-ST-HOI A Spatial-Temporal Baseline for Human-Object Interaction Detection in Videos [[paper](https://arxiv.org/abs/2105.11731)] [[code](https://github.com/coldmanck/VidHOI)] ![Github stars](https://img.shields.io/github/stars/coldmanck/VidHOI.svg)


## Dataset
  - CAD-120 [[paper](https://www.researchgate.net/publication/231609161_Learning_Human_Activities_and_Object_Affordances_from_RGB-D_Videos)] [[download(GoogleDrive)](https://drive.google.com/drive/folders/150LB6We_cqHfqf0RrYcI4OIZ-LoM0yNx)]
  - VidHOI [[paper](https://arxiv.org/abs/2105.11731)] [[download guide(github)](https://github.com/coldmanck/VidHOI)]
  - BimanualAction [[paper](https://arxiv.org/abs/1908.08391)] [[download(GoogleDrive)](https://drive.google.com/drive/folders/150LB6We_cqHfqf0RrYcI4OIZ-LoM0yNx)] [[download(official link)](https://bimanual-actions.humanoids.kit.edu/)]
  - AVA [[paper](http://openaccess.thecvf.com/content_cvpr_2018/html/Gu_AVA_A_Video_CVPR_2018_paper.html)] [[download(official link)](https://research.google.com/ava/download.html)]
  - ActGenome [[paper](http://openaccess.thecvf.com/content_CVPR_2020/html/Ji_Action_Genome_Actions_As_Compositions_of_Spatio-Temporal_Scene_Graphs_CVPR_2020_paper.html)] [[download(GoogleDrive)](https://drive.google.com/drive/folders/150LB6We_cqHfqf0RrYcI4OIZ-LoM0yNx)] [[download(official link)](https://www.actiongenome.org/)]

***
### context-aware emotion dataset (Video)
  - GroupWalk [[paper](http://openaccess.thecvf.com/content_CVPR_2020/html/Mittal_EmotiCon_Context-Aware_Multimodal_Emotion_Recognition_Using_Freges_Principle_CVPR_2020_paper.html)] [[download(official link)](https://gamma.umd.edu/researchdirections/affectivecomputing/emoticon/)]
  - AFEW [Face] 15 1809 clips, 7 emotion categories, from movie
  - CAER 30 13201 clips, 7 categories, from TV Show
  - IEMOCAP 9 12 hrs, 4 categories, from TV Show
  - GroupWalk 45 clips, 4 categories, from real scenario
  - 








